{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8XtcgbGj5xN"
   },
   "source": [
    "# Multiple Linear Regression for MNIST Images\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ag8Lj_RFPo9C"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "```\n",
    "\n",
    "\n",
    "* torch: The core PyTorch library for building neural networks.\n",
    "\n",
    "* torchvision: Provides popular datasets, model architectures, and image transformations. Useful for tasks like loading and transforming the MNIST dataset.\n",
    "\n",
    "* Variable: Used in earlier versions of PyTorch to wrap tensors, allowing automatic differentiation. However, this is now mostly unnecessary in recent versions of PyTorch as tensors themselves support autograd.\n",
    "\n",
    "# Hyperparameters:\n",
    "\n",
    "```\n",
    "n_epochs = 10\n",
    "batch_size_train = 200\n",
    "batch_size_test = 1000\n",
    "learning_rate = 1e-3\n",
    "momentum = 0.5\n",
    "log_interval = 100\n",
    "\n",
    "```\n",
    "* n_epochs: The number of times the model will iterate over the entire training dataset.\n",
    "\n",
    "* batch_size_train: The number of training samples processed before the model's parameters are updated.\n",
    "\n",
    "* batch_size_test: The batch size used during testing/evaluation.\n",
    "\n",
    "* learning_rate: The step size for the optimizer during gradient descent. Smaller values mean smaller updates, which can lead to more precise convergence but slower learning.\n",
    "\n",
    "* momentum: A hyperparameter often used in optimizers like stochastic gradient descent to accelerate convergence by considering the past gradients.\n",
    "\n",
    "* log_interval: The number of batches after which logs or status updates will be printed.\n",
    "\n",
    "# Random Seed\n",
    "\n",
    "```\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "```\n",
    "* random_seed = 1: A fixed seed ensures that the results are reproducible by controlling randomness in the model's initialization and operations.\n",
    "\n",
    "* torch.backends.cudnn.enabled = False: Disabling CUDA's cuDNN library to prevent non-deterministic behavior, though you can keep it enabled if performance is prioritized.\n",
    "\n",
    "* torch.manual_seed(random_seed): Sets the manual seed for PyTorch's random number generator, ensuring the model behaves consistently across runs.\n",
    "\n",
    "# GPU Availability Check:\n",
    "\n",
    "```\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "```\n",
    "\n",
    "* torch.device(): Checks if a GPU is available (cuda:0). If so, it will use the GPU for computation; otherwise, it falls back to the CPU.\n",
    "\n",
    "* print(device): Outputs the device being used (either cuda:0 or cpu).\n",
    "\n",
    "# Difference from Previous Code\n",
    "\n",
    "## Momentum and Learning Rate:\n",
    "This code introduces momentum and learning rate for a gradient-based optimization algorithm, which were not present in the previous code. This suggests a gradient-based approach (e.g., stochastic gradient descent or Adam) instead of the closed-form solution used earlier.\n",
    "\n",
    "##Epochs:\n",
    "The code defines n_epochs, implying that the model will be trained over multiple passes through the data. Previously, the training was done on a single batch using a closed-form solution.\n",
    "\n",
    "### Epoch Example\n",
    "Let’s assume you have a dataset of 1,000 images and you are training with a batch size of 100:\n",
    "\n",
    "In one epoch, the model will process the 1,000 images in batches of 100 images each. So, the model will perform 10 updates (1000 images / 100 batch size = 10 batches) to its weights.\n",
    "\n",
    "If you set n_epochs = 10, it means that the model will go through the entire dataset 10 times, resulting in 100 updates (10 epochs × 10 batches per epoch).\n",
    "\n",
    "###Why do we use multiple epochs?\n",
    "* Insufficient Learning: In a single epoch, the model might not learn the patterns well enough because the weight updates based on each batch are incremental.\n",
    "\n",
    "* Better Generalization: By passing through the data multiple times (with multiple epochs), the model has more opportunities to adjust its weights and improve its ability to generalize.\n",
    "\n",
    "##Batch Sizes:\n",
    "The introduction of batch_size_train and batch_size_test allows training and testing to happen in smaller mini-batches, making it possible to efficiently handle large datasets and potentially improve convergence through mini-batch gradient descent. Earlier, large batches were used in one shot.\n",
    "\n",
    "#Practical Example:\n",
    "If you're training a model on MNIST, with n_epochs = 10, the model will process the entire dataset 10 times. During training, the model will use batches of 200 images for updating the model parameters and will test in batches of 1000 images.\n",
    "\n",
    "The learning_rate and momentum will affect how fast and efficiently the model learns over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "j4BNOnZe46CQ",
    "outputId": "499b95e7-5f05-4b1d-fef4-7ec5dacb6829"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "\n",
    "n_epochs = 10\n",
    "batch_size_train = 200\n",
    "batch_size_test = 1000\n",
    "learning_rate = 1e-3\n",
    "momentum = 0.5\n",
    "log_interval = 100\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "# Checking GPU availability\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FWd5IGhbkCnz"
   },
   "source": [
    "# MNIST dataset is part of torchvision\n",
    "## Divide MNIST into training, validation and test sets\n",
    "## Use DataLoader iterator for loading data in batches\n",
    "\n",
    "This section of the code deals with loading the MNIST dataset, splitting it into training, validation, and test sets, and creating data loaders that are responsible for fetching batches of data during the training and evaluation processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8h41eZsXRWpW"
   },
   "source": [
    "# Importing random_split\n",
    "\n",
    "\n",
    "```\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "```\n",
    "random_split: This function is used to randomly divide a dataset into two or more subsets. In this case, it will split the MNIST dataset into training and validation sets.\n",
    "\n",
    "# Downloading and Preprocessing the MNIST Dataset:\n",
    "\n",
    "\n",
    "```\n",
    "MNIST_training = torchvision.datasets.MNIST('/MNIST_dataset/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "MNIST_test_set = torchvision.datasets.MNIST('/MNIST_dataset/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "```\n",
    "* torchvision.datasets.MNIST: Downloads the MNIST dataset (a popular handwritten digit dataset).\n",
    "\n",
    "* train=True: Loads the training set.\n",
    "\n",
    "* train=False: Loads the test set.\n",
    "\n",
    "* download=True: Downloads the dataset if it is not already present in the specified directory.\n",
    "\n",
    "* transform=torchvision.transforms.Compose([...]): Transforms the raw images. Here, it:\n",
    "    1. Converts the images to tensors: This is necessary because PyTorch models work with tensors.\n",
    "\n",
    "    2. Normalizes the images: The pixel values are normalized to have a mean of 0.1307 and a standard deviation of 0.3081 (common values for MNIST). This helps stabilize the learning process by keeping the input data on a similar scale.\n",
    "\n",
    "# Splitting the Training Dataset:\n",
    "```\n",
    "MNIST_training_set, MNIST_validation_set = random_split(MNIST_training, [55000, 5000])\n",
    "\n",
    "```\n",
    "random_split(MNIST_training, [55000, 5000]): The MNIST training set, which contains 60,000 images, is split into two parts:\n",
    "* Training set: 55,000 images.\n",
    "* Validation set: 5,000 images. (Used to evaluate the model during training and tune hyperparameters.)\n",
    "\n",
    "This split helps with hyperparameter tuning and prevents overfitting. The model is trained on the training set, and the validation set is used to assess performance and adjust parameters without seeing the test data.\n",
    "\n",
    "# Creating Data Loaders:\n",
    "```\n",
    "train_loader = torch.utils.data.DataLoader(MNIST_training_set, batch_size=batch_size_train, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(MNIST_validation_set, batch_size=batch_size_train, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(MNIST_test_set, batch_size=batch_size_test, shuffle=True)\n",
    "\n",
    "```\n",
    "Data loader make it easy to handle data batching, shuffling, and loading.\n",
    "\n",
    "* torch.utils.data.DataLoader: This is the PyTorch class that loads datasets in batches and shuffles them if needed.\n",
    "\n",
    "* batch_size=batch_size_train: Defines how many samples are included in each batch during training and validation (as defined earlier: 200 for training).\n",
    "\n",
    "* shuffle=True: Randomly shuffles the data at every epoch, which helps the model generalize better by preventing it from seeing the data in the same order every time.\n",
    "\n",
    "* test_loader: Loads the test set in batches of 1000 images. (Used for the final evaluation of the model's performance after training is complete.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Y2uiYpfC4_aW",
    "outputId": "97f25ced-e034-4fc3-cce1-dead98d85329"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 30] Read-only file system: '/MNIST_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m random_split\n\u001b[0;32m----> 4\u001b[0m MNIST_training \u001b[38;5;241m=\u001b[39m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMNIST\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/MNIST_dataset/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mToTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.1307\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.3081\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m MNIST_test_set \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mMNIST(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/MNIST_dataset/\u001b[39m\u001b[38;5;124m'\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m                              transform\u001b[38;5;241m=\u001b[39mtorchvision\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m     11\u001b[0m                                torchvision\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[1;32m     12\u001b[0m                                torchvision\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mNormalize((\u001b[38;5;241m0.1307\u001b[39m,), (\u001b[38;5;241m0.3081\u001b[39m,))]))\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# create a training and a validation set\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Projects/MNIST_MLR_M1/.venv/lib/python3.9/site-packages/torchvision/datasets/mnist.py:100\u001b[0m, in \u001b[0;36mMNIST.__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_exists():\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset not found. You can use download=True to download it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Projects/MNIST_MLR_M1/.venv/lib/python3.9/site-packages/torchvision/datasets/mnist.py:180\u001b[0m, in \u001b[0;36mMNIST.download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_exists():\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# download files\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename, md5 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresources:\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/os.py:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head \u001b[38;5;129;01mand\u001b[39;00m tail \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists(head):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexist_ok\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;66;03m# Defeats race condition when another thread created the path\u001b[39;00m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/os.py:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head \u001b[38;5;129;01mand\u001b[39;00m tail \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists(head):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexist_ok\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;66;03m# Defeats race condition when another thread created the path\u001b[39;00m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39misdir(name):\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 30] Read-only file system: '/MNIST_dataset'"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "\n",
    "MNIST_training = torchvision.datasets.MNIST('/MNIST_dataset/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize((0.1307,), (0.3081,))]))\n",
    "\n",
    "MNIST_test_set = torchvision.datasets.MNIST('/MNIST_dataset/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize((0.1307,), (0.3081,))]))\n",
    "\n",
    "# create a training and a validation set\n",
    "MNIST_training_set, MNIST_validation_set = random_split(MNIST_training, [55000, 5000])\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(MNIST_training_set,batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(MNIST_validation_set,batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(MNIST_test_set,batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vzUWismvsZeC"
   },
   "source": [
    "## Check DataLoader\n",
    "This section of code is responsible for fetching a batch of data from the test set and examining its structure (shape of the images and their corresponding labels). Let’s break down the steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "swy7l_V5S5MY"
   },
   "source": [
    "# Enumerating the Data Loader\n",
    "\n",
    "\n",
    "```\n",
    "examples = enumerate(test_loader)\n",
    "\n",
    "```\n",
    "enumerate(test_loader): This converts the test_loader (which is a DataLoader object) into an enumerated object.\n",
    "\n",
    "The enumerator returns both the batch index and the batch data (images and labels).\n",
    "\n",
    "Since test_loader loads the test set in batches (as specified earlier with batch_size_test), examples will allow us to iterate over the batches of test data.\n",
    "\n",
    "```\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "\n",
    "```\n",
    "* next(examples): This retrieves the next batch of data from the test_loader. In this case, since examples was just initialized, this will fetch the first batch from the test dataset.\n",
    "\n",
    "* batch_idx: The index of the batch (the first batch will have batch_idx = 0).\n",
    "\n",
    "* example_data: A tensor containing the images in the batch.\n",
    "example_targets: A tensor containing the corresponding labels (digits) for each image in the batch.\n",
    "\n",
    "```\n",
    "print(example_data.shape)\n",
    "print(example_targets.shape)\n",
    "\n",
    "```\n",
    "\n",
    "example_data.shape: This prints the shape of the image tensor (e.g., how many images are in the batch and the dimensions of each image).\n",
    "\n",
    "If the batch size is 1000, and each image is a 28x28 grayscale image, the shape would be [1000, 1, 28, 28].\n",
    "\n",
    "* 1000: The number of images in the batch.\n",
    "* 1: The number of channels (grayscale images have one channel).\n",
    "* 28, 28: The height and width of each image.\n",
    "\n",
    "example_targets.shape: This prints the shape of the labels tensor (i.e., how many labels correspond to the images in the batch). If the batch contains 1000 images, the shape will be [1000], representing the labels for those 1000 images.\n",
    "\n",
    "## Example Output:\n",
    "\n",
    "Assume batch_size_test = 1000. When you run this code, it might print something like this:\n",
    "\n",
    "torch.Size([1000, 1, 28, 28])\n",
    "torch.Size([1000])\n",
    "\n",
    "This tells you that:\n",
    "\n",
    "1. The first batch contains 1000 images, each of size 28x28 pixels.\n",
    "2. There are 1000 corresponding labels (one for each image).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "id": "PSq8BOG85GyN",
    "outputId": "a2c69460-eb3d-43a7-b05c-b106febee402"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 1, 28, 28])\n",
      "torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "print(example_data.shape)\n",
    "print(example_targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W4Bhye8YspZM"
   },
   "source": [
    "## Also, make sure to display some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "id": "g1hgLmOT5KsW",
    "outputId": "e0db1979-1271-4e1d-82e6-04a9234add78"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8POacovUkLx"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "```\n",
    "\n",
    "\n",
    "* torch.nn: The module that provides neural network components (e.g., layers).\n",
    "\n",
    "* torch.nn.functional: Contains functions for commonly used neural network operations like activation functions and loss functions.\n",
    "\n",
    "* torch.optim: Provides optimization algorithms, such as SGD, Adam, etc.\n",
    "\n",
    "* Variable: Used in earlier versions of PyTorch for wrapping tensors to allow automatic differentiation, though this is mostly redundant in recent versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aM32G_zp52dY"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBgEfm0pUc09"
   },
   "source": [
    "# Multiple Linear regression\n",
    "\n",
    "This section of code defines a Multiple Linear Regression model using PyTorch’s neural network module (torch.nn). The model will be used to classify the MNIST dataset, which consists of 28x28 grayscale images of handwritten digits. In this case, the task is to map each 28x28 image to one of 10 digits (0-9)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQ6a49SoUgQu"
   },
   "source": [
    "# Defining the Model Class:\n",
    "\n",
    "\n",
    "```\n",
    "class MultipleLinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultipleLinearRegression, self).__init__()\n",
    "        self.fc = nn.Linear(28*28, 10)\n",
    "\n",
    "```\n",
    "* class MultipleLinearRegression(nn.Module): This defines the model class for multiple linear regression. By inheriting from nn.Module, the model can make use of all the functionalities provided by PyTorch’s neural network module.\n",
    "\n",
    "* __init__(self): The constructor method initializes the layers of the model.\n",
    "\n",
    "* self.fc = nn.Linear(28*28, 10):\n",
    "  * This defines a fully connected (dense) layer, which takes the flattened 28x28 pixel image (784 input features) and outputs 10 values (corresponding to the 10 digits).\n",
    "  * Input size: 28*28 (784 features).\n",
    "  * Output size: 10 (each representing one of the digit classes: 0-9).\n",
    "\n",
    "# Forward Pass (Prediction):\n",
    "```\n",
    "def forward(self, x):\n",
    "    x = x.view(x.size(0), -1)\n",
    "    x = self.fc(x)\n",
    "    return x\n",
    "\n",
    "```\n",
    "def forward(self, x): This defines the forward pass, which describes how the input data is transformed as it passes through the layers of the model.\n",
    "\n",
    "## Flattening the Input:\n",
    "```\n",
    "x = x.view(x.size(0), -1)\n",
    "\n",
    "```\n",
    "* x.size(0): Refers to the batch size (the number of images in a batch).\n",
    "\n",
    "* x.view(x.size(0), -1): Flattens each image from a 2D shape (28x28) into a 1D vector of 784 elements. This is necessary because the fully connected layer expects a flat vector as input, not a 2D matrix.\n",
    "\n",
    "* For example, an MNIST batch of 200 images (batch size 200) would change shape from [200, 1, 28, 28] (200 grayscale images) to [200, 784] (200 flattened 28x28 images).\n",
    "\n",
    "## Applying the Linear Layer:\n",
    "```\n",
    "x = self.fc(x)\n",
    "\n",
    "```\n",
    "The input data x is passed through the fully connected layer (fc), which maps the 784 input features to 10 outputs (each representing one digit).\n",
    "\n",
    "## Returning the Output:\n",
    "```\n",
    "return x\n",
    "\n",
    "```\n",
    "The output of the forward pass is a tensor of shape [batch_size, 10], where each value corresponds to the predicted score (logits) for each digit (0-9).\n",
    "\n",
    "# Example of Input and Output:\n",
    "Input: A batch of MNIST images of shape [batch_size, 1, 28, 28]. After flattening, the input becomes [batch_size, 784].\n",
    "\n",
    "Output: A tensor of shape [batch_size, 10], where each row contains 10 values representing the logits (unnormalized scores) for each digit class (0-9). You can apply a softmax function to these logits to interpret them as probabilities for each digit.\n",
    "\n",
    "# Difference from Previous Code:\n",
    "1. **Introduction of a Neural Network Model:**\n",
    "This code defines a neural network using the nn.Module class, which was not part of the earlier code. Previously, the model was a linear regression-based solution where weights were computed using closed-form solutions. Now, the model uses a more flexible neural network that can be trained using gradient descent and backpropagation.\n",
    "\n",
    "2. **Linear Layer (nn.Linear):**\n",
    "This is a learnable layer with weights that can be updated during training, whereas the previous approach used a fixed set of weights calculated via a closed-form solution. The flexibility of nn.Linear allows for more powerful learning through iterative optimization (e.g., gradient descent).\n",
    "\n",
    "3. **Forward Method:**\n",
    "The forward() method defines how the input data moves through the model (input → flatten → linear layer → output). In previous code chunks, the model was more manual, relying on specific functions for prediction rather than an end-to-end neural network framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cd1MU6Yh56HF"
   },
   "outputs": [],
   "source": [
    "# Multiple Linear regression\n",
    "class MultipleLinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultipleLinearRegression, self).__init__()\n",
    "        self.fc = nn.Linear(28*28, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lEuX3iMXLRO"
   },
   "source": [
    "This section of the code sets up the model, defines the optimizer for training, and prepares for one-hot encoding of the target labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AUUTLnChXLzZ"
   },
   "source": [
    "# Model Initialization and Moving to Device:\n",
    "\n",
    "\n",
    "```\n",
    "multi_linear_model = MultipleLinearRegression().to(device)\n",
    "\n",
    "```\n",
    "* MultipleLinearRegression(): This creates an instance of the MultipleLinearRegression model that you defined earlier. It contains a single fully connected layer (nn.Linear(28*28, 10)), which is designed to take in the flattened MNIST images and output a prediction for one of the 10 digits (0-9).\n",
    "\n",
    "* .to(device): Moves the model to the appropriate computing device, either CPU or GPU (cuda:0), depending on what was detected earlier in the code. This ensures that all computations for the model will happen on the correct hardware.\n",
    "\n",
    "# Defining the Adam Optimizer:\n",
    "```\n",
    "optimizer = optim.Adam(multi_linear_model.parameters(), lr=learning_rate)\n",
    "```\n",
    "* optim.Adam: This defines the Adam optimizer, which is an adaptive learning rate optimization algorithm. Adam is one of the most popular optimizers because it combines the benefits of both SGD (stochastic gradient descent) and RMSProp by using momentum and adaptive learning rates.\n",
    "\n",
    "Why Adam?:\n",
    "It’s a robust and efficient optimizer that works well for many tasks. Unlike vanilla SGD, Adam adapts the learning rate for each parameter and uses momentum to accelerate convergence.\n",
    "\n",
    "* multi_linear_model.parameters(): This passes all the parameters (weights and biases) of the MultipleLinearRegression model to the optimizer. The optimizer will update these parameters during training to minimize the loss.\n",
    "\n",
    "* lr=learning_rate: This sets the learning rate (defined earlier as 1e-3). The learning rate controls how large a step the optimizer takes during each update.\n",
    "\n",
    "#One-Hot Encoding:\n",
    "```\n",
    "one_hot = torch.nn.functional.one_hot\n",
    "\n",
    "```\n",
    "torch.nn.functional.one_hot: This function will be used to one-hot encode the target labels. One-hot encoding is a process where a categorical variable (e.g., digit labels 0-9) is converted into a binary vector representation. Each class (digit) is represented by a vector where only one element is 1, and the rest are 0s.\n",
    "\n",
    "For example:\n",
    "\n",
    "Digit 2 → [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "Digit 7 → [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
    "\n",
    "This is important for classification tasks, especially when using loss functions like cross-entropy, which expect the target to be a one-hot encoded vector.\n",
    "\n",
    "# How It Works Together:\n",
    "\n",
    "Model (multi_linear_model):\n",
    "The MultipleLinearRegression model will take an MNIST image as input, flatten it to 784 features, and then output a set of 10 logits (one for each class, 0-9). These logits are the model's \"raw\" predictions before they are converted into probabilities (usually with softmax).\n",
    "\n",
    "Optimizer (optimizer):\n",
    "The Adam optimizer will adjust the model’s parameters (weights and biases) during training to reduce the error/loss between the predicted logits and the true labels. It uses the specified learning rate (1e-3) for this.\n",
    "\n",
    "One-Hot Encoding (one_hot):\n",
    "The true labels (e.g., digits 0-9) are converted into one-hot encoded vectors. These vectors will be compared against the model's predictions during training to compute the loss.\n",
    "\n",
    "# How it Differs from Previous Code:\n",
    "\n",
    "Model Training Setup:\n",
    "In previous code snippets, there was no optimizer for training. The earlier approach relied on closed-form solutions (like estimating parameters using direct matrix operations). This code, however, sets up an iterative training process using the Adam optimizer, which is more typical for deep learning models.\n",
    "\n",
    "Gradient-Based Optimization:\n",
    "The use of Adam represents a shift from the earlier approach (which didn’t use gradient descent). This optimizer will calculate gradients of the loss function and update the model’s parameters accordingly after every batch of data.\n",
    "\n",
    "One-Hot Encoding:\n",
    "The introduction of one-hot encoding suggests that the model will be trained using a classification loss function, like cross-entropy, which expects the target labels to be in a one-hot encoded form. This was not explicitly addressed in the earlier code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_hjjozQl6ARg"
   },
   "outputs": [],
   "source": [
    "multi_linear_model = MultipleLinearRegression().to(device)\n",
    "optimizer = optim.Adam(multi_linear_model.parameters(), lr=learning_rate)\n",
    "\n",
    "one_hot = torch.nn.functional.one_hot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mX9b-5J8YH_s"
   },
   "source": [
    "This function defines the training loop for one epoch of the model. The goal is to iterate over the dataset, compute predictions, calculate the loss, and update the model’s parameters using backpropagation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zU839ft0YP_J"
   },
   "source": [
    "# Function Definition:\n",
    "\n",
    "\n",
    "```\n",
    "def train(epoch, data_loader, model, optimizer):\n",
    "\n",
    "```\n",
    "* epoch: Indicates the current epoch (iteration over the entire dataset). Typically, the model is trained over multiple epochs to improve performance.\n",
    "\n",
    "* ata_loader: The training data loader that provides batches of images and their corresponding labels.\n",
    "model: The neural network model being trained (in this case, MultipleLinearRegression).\n",
    "\n",
    "* optimizer: The optimization algorithm (in this case, Adam), which updates the model’s parameters based on the computed gradients.\n",
    "\n",
    "# Iterating Over Batches:\n",
    "\n",
    "\n",
    "```\n",
    "for batch_idx, (data, target) in enumerate(data_loader):\n",
    "\n",
    "```\n",
    "* enumerate(data_loader): Loops through the dataset in mini-batches. For each iteration, data_loader returns a batch of input images (data) and their corresponding labels (target).\n",
    "\n",
    "* batch_idx: The index of the current batch. This is useful for tracking progress and logging status updates.\n",
    "\n",
    "# Move Data to the Appropriate Device:\n",
    "```\n",
    "data = data.to(device)\n",
    "target = target.to(device)\n",
    "\n",
    "```\n",
    ".to(device): Moves the batch of data and labels to the specified device (CPU or GPU). This ensures that all computations are performed on the same hardware (important when using GPUs for faster computation).\n",
    "\n",
    "# Zeroing the Gradients:\n",
    "```\n",
    "output = model(data)\n",
    "\n",
    "```\n",
    "optimizer.zero_grad(): Clears the old gradients from the previous step. This is necessary because, in PyTorch, gradients accumulate by default, so you need to reset them before computing new gradients during backpropagation.\n",
    "\n",
    "# Model Prediction:\n",
    "```\n",
    "output = model(data)\n",
    "\n",
    "```\n",
    "model(data): Passes the input data (images) through the model to get predictions. The output will be a tensor of shape [batch_size, 10], representing the logits for each class (0-9) for each image in the batch.\n",
    "\n",
    "# Calculating Loss:\n",
    "```\n",
    "loss = F.mse_loss(output, one_hot(target, num_classes=10).float())\n",
    "\n",
    "```\n",
    "* F.mse_loss(): Calculates the mean squared error (MSE) loss between the model’s predictions (output) and the true one-hot encoded labels.\n",
    "\n",
    "* output: The model’s predictions (logits) for each class.\n",
    "one_hot(target, num_classes=10).float(): Converts the true labels (target) into one-hot encoded vectors (0-9) for use in the loss function. The .float() ensures that the labels are in floating-point format, which is necessary for MSE loss.\n",
    "\n",
    "Why MSE Loss?\n",
    "Typically, for classification tasks, cross-entropy loss is used instead of MSE loss, as cross-entropy is better suited for measuring the difference between probabilities. However, in this case, MSE loss is being used, which penalizes the difference between the predicted values and the one-hot encoded targets.\n",
    "\n",
    "# Backpropagation:\n",
    "```\n",
    "loss.backward()\n",
    "\n",
    "```\n",
    "loss.backward(): Computes the gradients of the loss with respect to the model’s parameters using backpropagation. These gradients will be used to update the model’s weights during optimization.\n",
    "\n",
    "# Optimizer Step:\n",
    "\n",
    "```\n",
    "optimizer.step()\n",
    "\n",
    "```\n",
    "optimizer.step(): Updates the model’s parameters using the gradients computed during loss.backward(). This is where the model’s weights are adjusted to minimize the loss.\n",
    "\n",
    "# Logging Training Progress:\n",
    "\n",
    "```\n",
    "if batch_idx % log_interval == 0:\n",
    "  print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "    epoch, batch_idx * len(data), len(data_loader.dataset),\n",
    "    100. * batch_idx / len(data_loader), loss.item()))\n",
    "\n",
    "```\n",
    "* if batch_idx % log_interval == 0: Logs the training progress after every log_interval number of batches. This helps track the model’s performance throughout the epoch.\n",
    "\n",
    "* print(...): Displays information such as:\n",
    "  * The current epoch.\n",
    "  * The number of samples processed so far (batch_idx * len(data)).\n",
    "  * The total number of samples in the dataset (len(data_loader.dataset)).\n",
    "  * The percentage of the dataset processed so far (100. * batch_idx / len(data_loader)).\n",
    "  * The current loss (loss.item()).\n",
    "\n",
    "# How It Differs from the Previous Code:\n",
    "\n",
    "* Batch Training:\n",
    "In previous code examples, you did not have an explicit training loop. The current code introduces a typical mini-batch training loop where the model is trained using gradient descent over batches of data. The model parameters are updated after processing each mini-batch.\n",
    "\n",
    "* Loss Function:\n",
    "The earlier approach did not explicitly define a loss function. Here, you are using mean squared error (MSE) loss, which is a standard way to compute how far the model’s predictions are from the true labels. However, for classification tasks, cross-entropy loss is usually more effective.\n",
    "\n",
    "* Optimizer:\n",
    "The previous code relied on closed-form solutions for finding weights. In this code, you're using the Adam optimizer to iteratively adjust the model's parameters based on the gradients computed from the loss function. This allows the model to \"learn\" from the data gradually over multiple epochs.\n",
    "\n",
    "## Suggested Changes:\n",
    "Since this is a classification problem, you might want to use cross-entropy loss instead of MSE loss. Cross-entropy is better suited for multi-class classification tasks like MNIST.\n",
    "\n",
    "Here’s an alternative approach using cross-entropy loss:\n",
    "\n",
    "loss = F.cross_entropy(output, target)\n",
    "\n",
    "F.cross_entropy(): Automatically applies softmax to the output and calculates the cross-entropy loss between the predictions and the true labels (without needing to one-hot encode the targets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cy8SKSrG6KxV"
   },
   "outputs": [],
   "source": [
    "def train(epoch,data_loader,model,optimizer):\n",
    "  for batch_idx, (data, target) in enumerate(data_loader):\n",
    "    data = data.to(device)\n",
    "    target = target.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "    loss = F.mse_loss(output, one_hot(target,num_classes=10).float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_idx % log_interval == 0:\n",
    "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, batch_idx * len(data), len(data_loader.dataset),\n",
    "        100. * batch_idx / len(data_loader), loss.item()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rmVZtM9bZ22f"
   },
   "source": [
    "This function defines the evaluation process for a trained model on either the validation or test datasets. It computes the model’s loss and accuracy without modifying the model’s parameters (as we're not updating gradients in evaluation mode)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EsFPsSi2arnO"
   },
   "source": [
    "# Function Definition:\n",
    "\n",
    "\n",
    "```\n",
    "def eval(data_loader, model, dataset):\n",
    "\n",
    "```\n",
    "* data_loader: The loader for the dataset to be evaluated (either validation or test set).\n",
    "* model: The trained model whose performance is being evaluated.\n",
    "* dataset: A string indicating which dataset is being evaluated (e.g., \"validation\" or \"test\"), so that it can be printed in the output log.\n",
    "\n",
    "\n",
    "# Tracking Loss and Accuracy:\n",
    "```\n",
    "loss = 0\n",
    "correct = 0\n",
    "\n",
    "```\n",
    "* loss: Accumulates the total loss across all batches in the dataset.\n",
    "* correct: Counts the number of correctly predicted samples.\n",
    "\n",
    "# No Gradient Calculation:\n",
    "```\n",
    "with torch.no_grad():\n",
    "\n",
    "```\n",
    "torch.no_grad(): Disables gradient computation during evaluation, as gradients are not needed for inference (this reduces memory usage and speeds up computations). This is critical because evaluation should only compute predictions, not update model weights.\n",
    "\n",
    "# Iterating Over Batches:\n",
    "\n",
    "```\n",
    "for data, target in data_loader:\n",
    "  data = data.to(device)\n",
    "  target = target.to(device)\n",
    "\n",
    "```\n",
    "* for data, target in data_loader: Iterates over the dataset batch by batch, where data is the batch of images and target is the batch of labels.\n",
    "* data.to(device) and target.to(device): Moves the data and labels to the specified device (CPU or GPU) for computation.\n",
    "\n",
    "# Model Prediction:\n",
    "\n",
    "```\n",
    "output = model(data)\n",
    "\n",
    "```\n",
    "model(data): Passes the input data (images) through the model to get the predicted outputs. The output is a tensor of shape [batch_size, 10], representing the logits for each class (0-9).\n",
    "\n",
    "# Calculating Predictions:\n",
    "```\n",
    "pred = output.data.max(1, keepdim=True)[1]\n",
    "\n",
    "```\n",
    "* output.data.max(1, keepdim=True)[1]: This finds the index of the maximum value (logit) along dimension 1 (which corresponds to the 10 possible digit classes). This index is the predicted class for each input sample.\n",
    "  * For example, if the output logits are [0.1, 0.9, 0.05, ..., 0.02], the maximum value is 0.9, corresponding to class 1.\n",
    "* pred: Holds the predicted class labels for the batch.\n",
    "\n",
    "# Counting Correct Predictions:\n",
    "\n",
    "```\n",
    "correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "\n",
    "```\n",
    "* pred.eq(target.data.view_as(pred)): Compares the predicted labels (pred) with the true labels (target). It returns a tensor of True or False values for each comparison.\n",
    "* sum(): Counts how many predictions are correct by summing the True values.\n",
    "\n",
    "#  Calculating Loss:\n",
    "\n",
    "```\n",
    "loss += F.mse_loss(output, one_hot(target, num_classes=10).float(), size_average=False).item()\n",
    "\n",
    "```\n",
    "* F.mse_loss(output, one_hot(target, num_classes=10).float(), size_average=False): Computes the mean squared error (MSE) loss between the predicted logits (output) and the one-hot encoded true labels (target).\n",
    "\n",
    "* size_average=False: Accumulates the loss over all elements without averaging. This is necessary because you want the total loss across the entire dataset rather than the average per batch.\n",
    "\n",
    "* .item(): Extracts the scalar value of the loss from the tensor.\n",
    "\n",
    "#  Average Loss:\n",
    "\n",
    "```\n",
    "loss /= len(data_loader.dataset)\n",
    "\n",
    "```\n",
    "loss /= len(data_loader.dataset): Averages the total loss over all samples in the dataset to get the average loss per sample.\n",
    "\n",
    "\n",
    "# Printing the Results:\n",
    "\n",
    "```\n",
    "print(dataset + 'set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    loss, correct, len(data_loader.dataset), 100. * correct / len(data_loader.dataset)))\n",
    "\n",
    "```\n",
    "\n",
    "* dataset: Prints whether the evaluation is on the \"validation\" or \"test\" set.\n",
    "* loss: Displays the average loss per sample.\n",
    "* correct: The number of correctly classified samples.\n",
    "* len(data_loader.dataset): The total number of samples in the dataset.\n",
    "* 100. x correct / len(data_loader.dataset): Calculates and displays the accuracy as a percentage.\n",
    "\n",
    "# How It Differs from the Training Code:\n",
    "\n",
    "* No Gradients:\n",
    "In contrast to the training loop, the evaluation loop uses torch.no_grad() to disable gradient calculations. This makes evaluation faster and more memory-efficient since no gradients are needed for inference.\n",
    "\n",
    "* No Weight Updates:\n",
    "Unlike the training loop, this function doesn’t call optimizer.zero_grad(), loss.backward(), or optimizer.step(). The purpose of evaluation is to measure the model's performance, not to update its parameters.\n",
    "\n",
    "* Mean Squared Error Loss:\n",
    "Like the training function, this evaluation function uses mean squared error (MSE) loss, which is not typical for classification tasks. Normally, you would use cross-entropy loss for classification.\n",
    "\n",
    "You might want to replace this with cross-entropy loss for better evaluation of the model’s performance on a classification task.\n",
    "\n",
    "# Suggested Changes (Optional):\n",
    "Since the task is multi-class classification, using cross-entropy loss might be more appropriate than MSE loss.\n",
    "Here’s how you can adjust the loss calculation:\n",
    "\n",
    "```\n",
    "loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "```\n",
    "\n",
    "* F.cross_entropy(): Computes the cross-entropy loss, which is commonly used for classification tasks. It measures the difference between the predicted probability distribution (after applying softmax to the logits) and the true distribution.\n",
    "\n",
    "* reduction='sum': Accumulates the loss across all samples in the batch (similar to how size_average=False was used in MSE loss).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tr4Bd0BI6P7D"
   },
   "outputs": [],
   "source": [
    "def eval(data_loader,model,dataset):\n",
    "  loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad(): # notice the use of no_grad\n",
    "    for data, target in data_loader:\n",
    "      data = data.to(device)\n",
    "      target = target.to(device)\n",
    "      output = model(data)\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "      loss += F.mse_loss(output, one_hot(target,num_classes=10).float(), size_average=False).item()\n",
    "  loss /= len(data_loader.dataset)\n",
    "  print(dataset+'set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(loss, correct, len(data_loader.dataset), 100. * correct / len(data_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZBnrgjl_Z1rA"
   },
   "source": [
    "This section of code ties together the training and evaluation functions to complete the training process across multiple epochs and evaluate the model's performance on the validation and test datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VemiiBwDcTb5"
   },
   "source": [
    "# Initial Validation:\n",
    "\n",
    "\n",
    "```\n",
    "eval(validation_loader, multi_linear_model, \"Validation\")\n",
    "\n",
    "```\n",
    "* Before starting the training process, the code evaluates the model's performance on the validation set using the eval() function. This provides a baseline to compare the model's performance after training.\n",
    "* Purpose: Understand how the model performs with random initialization before training, giving you an idea of how much improvement occurs during training.\n",
    "\n",
    "# Training and Validation Loop:\n",
    "\n",
    "```\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  train(epoch, train_loader, multi_linear_model, optimizer)\n",
    "  eval(validation_loader, multi_linear_model, \"Validation\")\n",
    "\n",
    "```\n",
    "\n",
    "* for epoch in range(1, n_epochs + 1): This is the main training loop, which will run for n_epochs epochs (defined earlier as 10 epochs, for example).\n",
    "\n",
    "  For each epoch:\n",
    "\n",
    "  * Training: The model is trained on the training set using the train() function. In this function, the model’s parameters are updated using backpropagation and the optimizer.\n",
    "  * Validation: After each epoch, the model is evaluated on the validation set using the eval() function. This provides feedback on how well the model generalizes to unseen data during training.\n",
    "\n",
    "* Purpose: The validation step after each epoch allows you to track the model's performance and ensure it is improving over time without overfitting to the training set.\n",
    "\n",
    "# Final Test Evaluation:\n",
    "\n",
    "```\n",
    "eval(test_loader, multi_linear_model, \"Test\")\n",
    "\n",
    "```\n",
    "* After training is complete (after all epochs), the model is evaluated on the test set using the eval() function.\n",
    "* Purpose: The test set provides a final measure of how well the model performs on completely unseen data. Since the test set is only evaluated after the training process is complete, it serves as an unbiased assessment of the model’s performance.\n",
    "\n",
    "# Differences from Previous Code:\n",
    "\n",
    "* Epoch Loop:\n",
    "This code introduces the concept of training the model over multiple epochs (iterations over the entire dataset). Previously, there was no explicit handling of epochs.\n",
    "By repeating the training process over multiple epochs, the model has more chances to learn and improve its predictions.\n",
    "\n",
    "* Validation After Each Epoch:\n",
    "After every epoch, the model’s performance is evaluated on the validation set. This allows you to monitor how the model is generalizing as it learns.\n",
    "If the validation performance improves, it indicates the model is learning well. If it deteriorates, it could suggest overfitting.\n",
    "\n",
    "* Test Evaluation:\n",
    "After training is complete, the model is evaluated on the test set, which is completely independent of the training and validation data. This gives a reliable measure of the model's final performance.\n",
    "\n",
    "\n",
    "# Suggested Improvements:\n",
    "\n",
    "* Switch to Cross-Entropy Loss:\n",
    "If you're working with a classification problem like MNIST, it’s generally better to use cross-entropy loss rather than MSE loss for both training and evaluation. Cross-entropy is more suited to classification tasks as it penalizes the model more for incorrect class predictions.\n",
    "\n",
    "Update in the training loop:\n",
    "```\n",
    "loss = F.cross_entropy(output, target)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qRG7c7Sy6XOs",
    "outputId": "ceb21deb-3a61-4516-c6c3-adb0873c1dc9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nil_r\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validationset: Avg. loss: 3.5394, Accuracy: 684/5000 (14%)\n",
      "\n",
      "Train Epoch: 1 [0/55000 (0%)]\tLoss: 0.351442\n",
      "Train Epoch: 1 [20000/55000 (36%)]\tLoss: 0.053855\n",
      "Train Epoch: 1 [40000/55000 (73%)]\tLoss: 0.046262\n",
      "Validationset: Avg. loss: 0.4427, Accuracy: 4119/5000 (82%)\n",
      "\n",
      "Train Epoch: 2 [0/55000 (0%)]\tLoss: 0.039990\n",
      "Train Epoch: 2 [20000/55000 (36%)]\tLoss: 0.047258\n",
      "Train Epoch: 2 [40000/55000 (73%)]\tLoss: 0.045061\n",
      "Validationset: Avg. loss: 0.4277, Accuracy: 4088/5000 (82%)\n",
      "\n",
      "Train Epoch: 3 [0/55000 (0%)]\tLoss: 0.041757\n",
      "Train Epoch: 3 [20000/55000 (36%)]\tLoss: 0.036617\n",
      "Train Epoch: 3 [40000/55000 (73%)]\tLoss: 0.043163\n",
      "Validationset: Avg. loss: 0.4192, Accuracy: 4168/5000 (83%)\n",
      "\n",
      "Train Epoch: 4 [0/55000 (0%)]\tLoss: 0.040953\n",
      "Train Epoch: 4 [20000/55000 (36%)]\tLoss: 0.036207\n",
      "Train Epoch: 4 [40000/55000 (73%)]\tLoss: 0.040526\n",
      "Validationset: Avg. loss: 0.4345, Accuracy: 4158/5000 (83%)\n",
      "\n",
      "Train Epoch: 5 [0/55000 (0%)]\tLoss: 0.045445\n",
      "Train Epoch: 5 [20000/55000 (36%)]\tLoss: 0.040642\n",
      "Train Epoch: 5 [40000/55000 (73%)]\tLoss: 0.040115\n",
      "Validationset: Avg. loss: 0.4236, Accuracy: 4199/5000 (84%)\n",
      "\n",
      "Train Epoch: 6 [0/55000 (0%)]\tLoss: 0.041628\n",
      "Train Epoch: 6 [20000/55000 (36%)]\tLoss: 0.040218\n",
      "Train Epoch: 6 [40000/55000 (73%)]\tLoss: 0.039792\n",
      "Validationset: Avg. loss: 0.4166, Accuracy: 4205/5000 (84%)\n",
      "\n",
      "Train Epoch: 7 [0/55000 (0%)]\tLoss: 0.040378\n",
      "Train Epoch: 7 [20000/55000 (36%)]\tLoss: 0.042461\n",
      "Train Epoch: 7 [40000/55000 (73%)]\tLoss: 0.038644\n",
      "Validationset: Avg. loss: 0.4157, Accuracy: 4179/5000 (84%)\n",
      "\n",
      "Train Epoch: 8 [0/55000 (0%)]\tLoss: 0.041326\n",
      "Train Epoch: 8 [20000/55000 (36%)]\tLoss: 0.042946\n",
      "Train Epoch: 8 [40000/55000 (73%)]\tLoss: 0.040057\n",
      "Validationset: Avg. loss: 0.4157, Accuracy: 4151/5000 (83%)\n",
      "\n",
      "Train Epoch: 9 [0/55000 (0%)]\tLoss: 0.041751\n",
      "Train Epoch: 9 [20000/55000 (36%)]\tLoss: 0.045056\n",
      "Train Epoch: 9 [40000/55000 (73%)]\tLoss: 0.040350\n",
      "Validationset: Avg. loss: 0.4134, Accuracy: 4171/5000 (83%)\n",
      "\n",
      "Train Epoch: 10 [0/55000 (0%)]\tLoss: 0.038169\n",
      "Train Epoch: 10 [20000/55000 (36%)]\tLoss: 0.043347\n",
      "Train Epoch: 10 [40000/55000 (73%)]\tLoss: 0.040188\n",
      "Validationset: Avg. loss: 0.4205, Accuracy: 4148/5000 (83%)\n",
      "\n",
      "Testset: Avg. loss: 0.4174, Accuracy: 8422/10000 (84%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval(validation_loader,multi_linear_model,\"Validation\")\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  train(epoch,train_loader,multi_linear_model,optimizer)\n",
    "  eval(validation_loader,multi_linear_model,\"Validation\")\n",
    "\n",
    "eval(test_loader,multi_linear_model,\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ZYFPokHPbzd",
    "outputId": "d09840e4-11be-4ef3-bee9-95f841f15f1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0298,  0.0274, -0.0073,  ...,  0.0215, -0.0161, -0.0049],\n",
      "        [-0.0154, -0.0141, -0.0172,  ..., -0.0080, -0.0115,  0.0375],\n",
      "        [-0.0010, -0.0379,  0.0218,  ...,  0.0312, -0.0182,  0.0036],\n",
      "        ...,\n",
      "        [ 0.0226, -0.0288, -0.0309,  ..., -0.0332, -0.0200, -0.0127],\n",
      "        [ 0.0021, -0.0285, -0.0341,  ..., -0.0154,  0.0063,  0.0105],\n",
      "        [ 0.0343, -0.0328,  0.0351,  ..., -0.0223,  0.0158,  0.0015]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0096, -0.0403, -0.0117,  0.0213, -0.0281,  0.0327, -0.0002,  0.0195,\n",
      "         0.0198,  0.0148], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in multi_linear_model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECEcKuyXPbze"
   },
   "source": [
    "# Gradient Descent Without Using PyTorch Autograd or Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ipJ-Y90tPbze"
   },
   "outputs": [],
   "source": [
    "def myGD_train(epoch,data_loader,model,learning_rate):\n",
    "  for batch_idx, (data, target) in enumerate(data_loader):\n",
    "    data = data.to(device)\n",
    "    target = target.to(device)\n",
    "    output = model(data)\n",
    "    one_hot_target = one_hot(target,num_classes=10).float()\n",
    "    loss = F.mse_loss(output, one_hot_target)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        W = list(model.parameters())[0]\n",
    "        b = list(model.parameters())[1]\n",
    "        X = data.view(data.size(0), -1)\n",
    "        gradW = torch.mm(torch.mm(X.T,X),W.T) - torch.mm(X.T,one_hot_target)\n",
    "        gradW = gradW.T\n",
    "        W.copy_(W - learning_rate*gradW)\n",
    "        gradb = torch.sum(output - one_hot_target,dim=0)\n",
    "        b.copy_(b - learning_rate*gradb)\n",
    "\n",
    "    if batch_idx % log_interval == 0:\n",
    "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, batch_idx * len(data), len(data_loader.dataset),\n",
    "        100. * batch_idx / len(data_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CLRMZ0LbPbze",
    "outputId": "4e366496-8cbd-4ac1-e7dc-06ca46b4abf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validationset: Avg. loss: 3.4181, Accuracy: 551/5000 (11%)\n",
      "\n",
      "Train Epoch: 1 [0/55000 (0%)]\tLoss: 0.328529\n",
      "Train Epoch: 1 [20000/55000 (36%)]\tLoss: 0.091775\n",
      "Train Epoch: 1 [40000/55000 (73%)]\tLoss: 0.072018\n",
      "Validationset: Avg. loss: 0.6670, Accuracy: 3663/5000 (73%)\n",
      "\n",
      "Train Epoch: 2 [0/55000 (0%)]\tLoss: 0.066246\n",
      "Train Epoch: 2 [20000/55000 (36%)]\tLoss: 0.062084\n",
      "Train Epoch: 2 [40000/55000 (73%)]\tLoss: 0.050475\n",
      "Validationset: Avg. loss: 0.5661, Accuracy: 3897/5000 (78%)\n",
      "\n",
      "Train Epoch: 3 [0/55000 (0%)]\tLoss: 0.055494\n",
      "Train Epoch: 3 [20000/55000 (36%)]\tLoss: 0.053325\n",
      "Train Epoch: 3 [40000/55000 (73%)]\tLoss: 0.053025\n",
      "Validationset: Avg. loss: 0.5212, Accuracy: 3999/5000 (80%)\n",
      "\n",
      "Train Epoch: 4 [0/55000 (0%)]\tLoss: 0.052647\n",
      "Train Epoch: 4 [20000/55000 (36%)]\tLoss: 0.046624\n",
      "Train Epoch: 4 [40000/55000 (73%)]\tLoss: 0.049767\n",
      "Validationset: Avg. loss: 0.4947, Accuracy: 4039/5000 (81%)\n",
      "\n",
      "Train Epoch: 5 [0/55000 (0%)]\tLoss: 0.048952\n",
      "Train Epoch: 5 [20000/55000 (36%)]\tLoss: 0.048975\n",
      "Train Epoch: 5 [40000/55000 (73%)]\tLoss: 0.048572\n",
      "Validationset: Avg. loss: 0.4773, Accuracy: 4067/5000 (81%)\n",
      "\n",
      "Train Epoch: 6 [0/55000 (0%)]\tLoss: 0.045599\n",
      "Train Epoch: 6 [20000/55000 (36%)]\tLoss: 0.049020\n",
      "Train Epoch: 6 [40000/55000 (73%)]\tLoss: 0.044150\n",
      "Validationset: Avg. loss: 0.4643, Accuracy: 4086/5000 (82%)\n",
      "\n",
      "Train Epoch: 7 [0/55000 (0%)]\tLoss: 0.047768\n",
      "Train Epoch: 7 [20000/55000 (36%)]\tLoss: 0.044947\n",
      "Train Epoch: 7 [40000/55000 (73%)]\tLoss: 0.042374\n",
      "Validationset: Avg. loss: 0.4540, Accuracy: 4106/5000 (82%)\n",
      "\n",
      "Train Epoch: 8 [0/55000 (0%)]\tLoss: 0.050187\n",
      "Train Epoch: 8 [20000/55000 (36%)]\tLoss: 0.047072\n",
      "Train Epoch: 8 [40000/55000 (73%)]\tLoss: 0.046354\n",
      "Validationset: Avg. loss: 0.4471, Accuracy: 4118/5000 (82%)\n",
      "\n",
      "Train Epoch: 9 [0/55000 (0%)]\tLoss: 0.045556\n",
      "Train Epoch: 9 [20000/55000 (36%)]\tLoss: 0.046179\n",
      "Train Epoch: 9 [40000/55000 (73%)]\tLoss: 0.043892\n",
      "Validationset: Avg. loss: 0.4397, Accuracy: 4146/5000 (83%)\n",
      "\n",
      "Train Epoch: 10 [0/55000 (0%)]\tLoss: 0.044125\n",
      "Train Epoch: 10 [20000/55000 (36%)]\tLoss: 0.043577\n",
      "Train Epoch: 10 [40000/55000 (73%)]\tLoss: 0.042055\n",
      "Validationset: Avg. loss: 0.4345, Accuracy: 4148/5000 (83%)\n",
      "\n",
      "Testset: Avg. loss: 0.4290, Accuracy: 8455/10000 (85%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multi_linear_model = MultipleLinearRegression().to(device)\n",
    "\n",
    "eval(validation_loader,multi_linear_model,\"Validation\")\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  myGD_train(epoch,train_loader,multi_linear_model,0.00001)\n",
    "  eval(validation_loader,multi_linear_model,\"Validation\")\n",
    "\n",
    "eval(test_loader,multi_linear_model,\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7PDLeMRqPbze"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
